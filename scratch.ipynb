{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4430e74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 0) Tokenizer & constants\n",
    "# --------------------------\n",
    "from transformers import EsmTokenizer\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "import math, random\n",
    "\n",
    "tokenizer = EsmTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "MASK_ID = tokenizer.mask_token_id\n",
    "PAD_ID  = tokenizer.pad_token_id\n",
    "BOS_ID  = tokenizer.bos_token_id\n",
    "EOS_ID  = tokenizer.eos_token_id\n",
    "\n",
    "# canonical 20 amino acids (generation allowlist)\n",
    "CANON = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "CANON_IDS = tokenizer.convert_tokens_to_ids(CANON)\n",
    "CANON_IDS_T = None  # filled lazily on device\n",
    "\n",
    "def encode_core(seq: str) -> torch.LongTensor:\n",
    "    \"\"\"Return core token ids [L] without BOS/EOS.\"\"\"\n",
    "    ids = tokenizer(seq, add_special_tokens=True, return_tensors=\"pt\")[\"input_ids\"][0]\n",
    "    return ids[1:-1].clone()\n",
    "\n",
    "def batch_encode_core(seqs):\n",
    "    ids = tokenizer(\n",
    "        seqs, add_special_tokens=True, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    )[\"input_ids\"]              # [B, L+2]\n",
    "    return ids[:, 1:-1].contiguous()  # [B, L]\n",
    "\n",
    "def decode_core(core_ids: torch.LongTensor) -> str:\n",
    "    \"\"\"core_ids: [L]; return string of AAs (drop specials).\"\"\"\n",
    "    toks = tokenizer.convert_ids_to_tokens(core_ids.tolist())\n",
    "    # strip anything non-canonical just in case\n",
    "    toks = [t if t in CANON else \"A\" for t in toks]\n",
    "    return \"\".join(toks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69f8cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 1) Schedules: alpha(t), alpha'(t)\n",
    "# --------------------------\n",
    "def alpha_cosine(t: torch.Tensor) -> torch.Tensor:\n",
    "    # alpha(t) = cos^2(pi/2 * t)\n",
    "    return torch.cos(0.5 * math.pi * t).pow(2)\n",
    "\n",
    "def alpha_prime_cosine(t: torch.Tensor) -> torch.Tensor:\n",
    "    # derivative of cos^2(π t / 2) = -π/2 * sin(π t)\n",
    "    # more precisely: d/dt cos^2(a t) = -a*sin(2 a t)\n",
    "    a = 0.5 * math.pi\n",
    "    return -2*a*torch.cos(a*t)*torch.sin(a*t)\n",
    "\n",
    "def weight_w(t: torch.Tensor) -> torch.Tensor:\n",
    "    a = alpha_cosine(t)\n",
    "    ap = alpha_prime_cosine(t)\n",
    "    return ap / (1.0 - a).clamp_min(1e-6)  # Eq. (47) factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aa6835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 2) Forward masking q_t (absorbing state)\n",
    "# --------------------------\n",
    "def forward_mask(core_ids: torch.LongTensor, t_scalar: float):\n",
    "    \"\"\"\n",
    "    core_ids: [B, L], ints. t_scalar in [0,1].\n",
    "    Replace each token with MASK_ID iid with prob 1 - alpha(t).\n",
    "    Returns: z_t [B,L], mask_bool [B,L] of positions that were masked.\n",
    "    \"\"\"\n",
    "    B, L = core_ids.shape\n",
    "    t = torch.full((B,), float(t_scalar), device=core_ids.device)\n",
    "    a = alpha_cosine(t).view(B, 1)\n",
    "    p_mask = 1.0 - a  # per-batch; broadcast over length\n",
    "    U = torch.rand(B, L, device=core_ids.device)\n",
    "    mask = U < p_mask\n",
    "    z_t = core_ids.clone()\n",
    "    z_t[mask] = MASK_ID\n",
    "    return z_t, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238ce840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 3) Denoiser: encoder-only Transformer + time conditioning\n",
    "# --------------------------\n",
    "class TimeEmbed(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Linear(d_model, 4*d_model), nn.SiLU(), nn.Linear(4*d_model, d_model)\n",
    "        )\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, t_scalar: float, device):\n",
    "        # sinusoidal TE of size d_model\n",
    "        t = torch.tensor([t_scalar], device=device).float()\n",
    "        half = self.d_model // 2\n",
    "        freqs = torch.exp(-math.log(10000.0) * torch.arange(half, device=device)/half)\n",
    "        ang = t[:, None] * freqs[None, :]\n",
    "        te = torch.cat([ang.sin(), ang.cos()], dim=-1)  # [1, d_model]\n",
    "        return self.lin(te)  # [1, d_model]\n",
    "\n",
    "class MDLMTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=768, n_layers=12, n_heads=12, max_len=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos   = nn.Embedding(max_len, d_model)\n",
    "        enc = nn.TransformerEncoderLayer(\n",
    "            d_model, n_heads, 4*d_model, dropout=dropout, batch_first=True, norm_first=True\n",
    "        )\n",
    "        self.tr = nn.TransformerEncoder(enc, num_layers=n_layers)\n",
    "        self.to_logits = nn.Linear(d_model, vocab_size, bias=False)\n",
    "        self.to_logits.weight = self.embed.weight  # tie weights\n",
    "        self.time = TimeEmbed(d_model)\n",
    "\n",
    "    def forward(self, core_ids: torch.LongTensor, t_scalar: float):\n",
    "        \"\"\"\n",
    "        core_ids: [B, L] (NO BOS/EOS). Returns logits over vocab: [B, L, V].\n",
    "        \"\"\"\n",
    "        B, L = core_ids.shape\n",
    "        pos = self.pos.weight[:L][None, ...].expand(B, L, -1)\n",
    "        h = self.embed(core_ids) + pos + self.time(t_scalar, device=core_ids.device)\n",
    "        h = self.tr(h)\n",
    "        return self.to_logits(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98312aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 4) MDLM loss step (Algorithm 1)\n",
    "# --------------------------\n",
    "def mdlm_loss_step(model, core_ids, t_scalar: float):\n",
    "    \"\"\"\n",
    "    core_ids: [B,L] clean targets.\n",
    "    1) sample z_t by masking with prob 1-alpha(t)\n",
    "    2) predict logits on z_t\n",
    "    3) CE on masked positions only\n",
    "    4) weight by w(t) = alpha'(t)/(1-alpha(t))\n",
    "    \"\"\"\n",
    "    z_t, masked = forward_mask(core_ids, t_scalar)\n",
    "    logits = model(z_t, t_scalar)  # [B,L,V]\n",
    "\n",
    "    # CE only on masked positions\n",
    "    if not masked.any():\n",
    "        return logits.new_tensor(0.0, requires_grad=True)\n",
    "\n",
    "    # Gather targets at masked sites\n",
    "    targets = core_ids[masked]  # [Nmask]\n",
    "    logits_m = logits[masked]   # [Nmask, V]\n",
    "\n",
    "    loss = F.cross_entropy(logits_m, targets, reduction=\"mean\")\n",
    "    # weight per Eq. (47)\n",
    "    w = weight_w(torch.tensor([t_scalar], device=logits.device)).item()\n",
    "    return loss * float(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1627954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 5) Trainer skeleton\n",
    "# --------------------------\n",
    "def train_mdlm(model, dataloader, epochs=1, lr=3e-4, device=\"cuda\"):\n",
    "    model.to(device)\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    model.train()\n",
    "    for ep in range(epochs):\n",
    "        for batch_core in dataloader:              # batch_core: [B,L]\n",
    "            batch_core = batch_core.to(device)\n",
    "            t_scalar = random.random()              # t ~ U[0,1]\n",
    "            loss = mdlm_loss_step(model, batch_core, t_scalar)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optim.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13620ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 6) Ancestral sampling (SUBS) with unmask probability\n",
    "# --------------------------\n",
    "@torch.no_grad()\n",
    "def ancestral_sample_mdlm(model, seq_len, T=64, top_p=0.9, temperature=1.0, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Start all MASK, descend t=1..0 with T steps.\n",
    "    At each step unmask a fraction p_unmask = (alpha_s - alpha_t)/(1 - alpha_t) of the remaining masks\n",
    "    by sampling from the model's categorical; carry-over for unmasked tokens.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x = torch.full((1, seq_len), MASK_ID, dtype=torch.long, device=device)  # core tokens\n",
    "    global CANON_IDS_T\n",
    "    if CANON_IDS_T is None:\n",
    "        CANON_IDS_T = torch.tensor(CANON_IDS, device=device, dtype=torch.long)\n",
    "\n",
    "    for step in range(T, 0, -1):\n",
    "        t = step / T\n",
    "        s = (step - 1) / T\n",
    "        a_t = alpha_cosine(torch.tensor([t], device=device))\n",
    "        a_s = alpha_cosine(torch.tensor([s], device=device))\n",
    "        p_unmask = ((a_s - a_t) / (1 - a_t).clamp_min(1e-6)).clamp(0, 1).item()\n",
    "\n",
    "        logits = model(x, t)            # [1, L, V]\n",
    "        # clamp to 20 AAs\n",
    "        V = logits.size(-1)\n",
    "        bans = torch.ones(V, dtype=torch.bool, device=device)\n",
    "        bans[CANON_IDS_T] = False\n",
    "        logits[..., bans] = float(\"-inf\")\n",
    "\n",
    "        # nucleus sampling for proposed tokens (only for masked positions)\n",
    "        probs = (logits / temperature).softmax(-1)  # [1,L,V]\n",
    "        # nucleus filter\n",
    "        sorted_p, idx = probs.sort(-1, descending=True)\n",
    "        csum = sorted_p.cumsum(-1)\n",
    "        cutoff = (csum > top_p).float().argmax(-1, keepdim=True)\n",
    "        keep = torch.arange(V, device=device)[None, None, :] <= cutoff\n",
    "        keep = keep.gather(-1, idx.argsort(-1))\n",
    "        probs = probs * keep\n",
    "        probs = probs / probs.sum(-1, keepdim=True)\n",
    "\n",
    "        sampled = torch.distributions.Categorical(probs=probs).sample()  # [1, L]\n",
    "\n",
    "        # choose which masked positions to unmask this step\n",
    "        masked_now = (x == MASK_ID)\n",
    "        if masked_now.any():\n",
    "            k = int(p_unmask * masked_now.sum().item())\n",
    "            if k > 0:\n",
    "                # unmask the k positions with highest confidence (max prob) among masked\n",
    "                maxp = probs.max(-1).values  # [1, L]\n",
    "                maxp_masked = maxp.masked_fill(~masked_now, -1)\n",
    "                topk_idx = torch.topk(maxp_masked, k=k, dim=-1).indices\n",
    "                x[0, topk_idx[0]] = sampled[0, topk_idx[0]]\n",
    "        # carry-over for already unmasked happens implicitly (we never change them)\n",
    "\n",
    "    # decode to string\n",
    "    return decode_core(x[0].cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7573cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"dahvid12/uniprot50-sequences-subsample100\")\n",
    "sequences = pd.Series(ds[\"train\"][\"sequence\"])\n",
    "print(sequences.head())\n",
    "\n",
    "vocab_size = tokenizer.vocab_size\n",
    "model = MDLMTransformer(vocab_size=vocab_size, d_model=512, n_layers=12, n_heads=8)\n",
    "\n",
    "# Example tiny loop (pseudo)\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "seqs = sequences.tolist()  # your corpus\n",
    "core = batch_encode_core(seqs)            # [B,L]\n",
    "ds = TensorDataset(core)                  # pack as 1-tensor dataset\n",
    "dl = DataLoader(ds, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0309fd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_mdlm(model, (b[0] for b in dl), epochs=10, lr=3e-4, device=\"cuda\")\n",
    "sample = ancestral_sample_mdlm(model, seq_len=256, T=64, device=\"cuda\")\n",
    "print(sample)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protDiffuse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
